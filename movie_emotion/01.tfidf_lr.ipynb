{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:11:49.307412Z",
     "start_time": "2019-09-05T12:11:49.260612Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "TRAIN_FILE = './data/train_data.csv'\n",
    "TEST_FILE = './data/test_data.csv'\n",
    "SUBMIT_FILE = './data/tfidf_lr_submission.csv'\n",
    "\n",
    "class TF_IDF_LR():\n",
    "    def __init__(self, input_file,  input_file_encoding, stop_words_file=False):\n",
    "        '''\n",
    "        input_file:          输入文件名\n",
    "        input_file_encoding：输入文件编码格式\n",
    "        stop_words_file：    停顿词文件名，无停顿词时设置为False\n",
    "        '''\n",
    "        self.input_file = input_file\n",
    "        self.input_file_encoding = input_file_encoding\n",
    "        self.stop_words_file = stop_words_file\n",
    "        \n",
    "    def load_data(self):\n",
    "        '''\n",
    "        利用pandas加载数据到dataframe\n",
    "        '''\n",
    "        return pd.read_csv(self.input_file, encoding=self.input_file_encoding)\n",
    "    \n",
    "    def get_data(self, test_size=0.1):\n",
    "        '''\n",
    "        取得数据的特征列和标签列，对特征列进行分词的处理，然后划分数据集为训练集和测试集\n",
    "        '''\n",
    "        df = self.load_data()\n",
    "        X = df['comment'].apply(self.jieba_tokenizer)\n",
    "        y = df['label']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        #出现频率最高的几个，对评价无影响的词,最后未使用\n",
    "        #excludeWords = {'的','了','我','看','电影','在'}\n",
    "        excludeWords = {}\n",
    "        \n",
    "        #没有max_features:0.812344\n",
    "        #max_features = 500    #0.766281\n",
    "        #max_features = 1000   #0.772181\n",
    "        #max_features = 1500   #0.794872\n",
    "        #max_features = 2000   #0.795326\n",
    "        #max_features = 3000   #0.804402\n",
    "        #max_features = 4000   #0.804629\n",
    "        #max_features = 5000   #0.809621\n",
    "        #max_features = 6000   #0.811436\n",
    "        #max_features = 7000   #0.810302\n",
    "        #max_features = 8000   #0.811436\n",
    "        #max_features = 9000   #0.815975\n",
    "        max_features = 10000  #0.811436\n",
    "        #max_features = 11000   #0.818017\n",
    "        #max_features = 12000   #0.815067\n",
    "        #max_features = 15000    #0.812798\n",
    "        #max_features = 11000 \n",
    "        self.tfidf_vec = TfidfVectorizer(smooth_idf=1,\n",
    "                            analyzer='word',\n",
    "                            encoding='utf-8',\n",
    "                            preprocessor=None,\n",
    "                            ngram_range=(1, 2),\n",
    "                            max_features = max_features,\n",
    "                            stop_words=excludeWords)   #812798\n",
    "                                   \n",
    "    \n",
    "        # 使用tfidf的方式，将原始训练和测试文本转化为特征向量。\n",
    "        X_tfidf_train = self.tfidf_vec.fit_transform(self.X_train)\n",
    "        X_tfidf_test = self.tfidf_vec.transform(self.X_test)\n",
    "    \n",
    "        lr = LogisticRegression()\n",
    "        lr = lr.fit(X_tfidf_train, self.y_train)\n",
    "\n",
    "        print('Test set accuracy: %3f' % lr.score(X_tfidf_test, self.y_test))\n",
    "        \n",
    "        self.model = lr\n",
    "    def jieba_tokenizer(self,x):\n",
    "        '''\n",
    "        对输入进行分词处理，然后词语之间以空格分割的形式返回字符串\n",
    "        '''\n",
    "        words =  jieba.cut(x,cut_all=True)\n",
    "        return \" \".join(words)\n",
    "    \n",
    "    def predict(self, test_file, submit_file):\n",
    "        test_df = pd.read_csv(test_file,  encoding='utf-8', header=0)\n",
    "        #将行按空格分割\n",
    "        X = test_df['comment'].apply(self.jieba_tokenizer) \n",
    "        \n",
    "        #将词转换为向量\n",
    "        X_vect = self.tfidf_vec.transform(X)\n",
    "        \n",
    "        #预测\n",
    "        y_pred = self.model.predict(X_vect)\n",
    "        \n",
    "        #预测结果保存\n",
    "        res = pd.DataFrame({'label':y_pred})\n",
    "        res.to_csv(submit_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:12:06.202242Z",
     "start_time": "2019-09-05T12:11:57.403827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.825505\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf_idf = TF_IDF_LR(TRAIN_FILE, 'utf-8')\n",
    "    tf_idf.get_data()\n",
    "    tf_idf.train()\n",
    "    tf_idf.predict(TEST_FILE, SUBMIT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T12:30:30.781787Z",
     "start_time": "2019-09-05T12:30:30.750587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9512\n"
     ]
    }
   ],
   "source": [
    "#评价本次预测结果和之前提交的xlgao_submission.csv的差别有多大， xlgao_submission.csv的正确率为0.82左右\n",
    "#如果差别太大，表示错误率比起之前提交版本还差，没有必要提交\n",
    "\n",
    "from utils import calculate_accurate\n",
    "file1 = \"./data/tfidf_lr_submission.csv\"\n",
    "file2 = \"./data/xlgao_submission.csv\"\n",
    "\n",
    "calculate_accurate(file1, file2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
